project: sd-3b-from-scratch # Insert wandb project name
batch_size: 4096
seed: 17
scale_schedule_ratio: 1.0
name: pexels-3b-speed-test # Insert wandb run name
eval_first: false

# algorithms:
#   low_precision_groupnorm:
#     attribute: unet
#     precision: amp_fp16
#   low_precision_layernorm:
#     attribute: unet
#     precision: amp_fp16

text_encoders_path:
  clip_G: /mnt/CV_teamz/pretrained/CLIP-ViT-bigG-14-laion2B-39B-b160k/
  clip_B: /mnt/CV_teamz/pretrained/stable-diffusion-v1-4/
  t5_L: /mnt/CV_teamz/pretrained/flan-t5-xxl

tokenizer:
  _target_: diffusion.datasets.multi_tokenizer.MultiTokenizer
  tokenizers_path: ${text_encoders_path}
  clip_max_length: 77
  t5_max_length: 231
  fast_version: False

model:
  _target_: diffusion.models.models_3B.stable_diffusion_3B
  model_name: /mnt/CV_teamz/pretrained/stable-diffusion-2-1
  text_encoders: ${text_encoders_path}
  # tokenizer: ${tokenizer}
  unet_model_config_path: unet_config/config.json
  prediction_type: v_prediction
  encode_latents_in_fp16: false
  fsdp: false
  val_metrics:
    - _target_: torchmetrics.MeanSquaredError
  val_guidance_scales: []
  loss_bins: []

dataset:
  train_batch_size: ${batch_size}
  eval_batch_size: 1024 # Should be 8 per device
  train_dataset:
    _target_: diffusion.datasets.mix_datapipe.build_mix_dataloader
    datapipes:
      laion:
        _target_: diffusion.datasets.wds.WdsDatapipe
        data_path: /mnt/CV_550w/LAION5B-clean/afs-laion2b.json
        filter_strategy: ~
        weight: 5.3
      coyo:
        _target_: diffusion.datasets.wds.WdsDatapipe
        data_path: /mnt/CV_550w/datasets/afs-coyo.json
        filter_strategy: ~
        weight: 2.1
      cc:
        _target_: diffusion.datasets.wds.WdsDatapipe
        data_path: /mnt/CV_550w/datasets/afs-cc-all.json
        filter_strategy: ~
        weight: 0.06
    batch_size: ${batch_size}
    petrel_conf: /mnt/CV_teamz/open_datasets/datasets/LAION-5b/config/petreloss.tmp.conf
    # tokenizer: ${tokenizer}
    filter_strategy: ~
    caption_drop_prob: 0.0
    resize_size: 256
    num_workers: 1
    prefetch_count: 8
    shuffle: true
    drop_last: true
    seed: ${seed}
  eval_dataset:
    _target_: diffusion.datasets.pexels.pexels_datapipe.build_pexels_dataloader
    data_path: /mnt/CV_teamz/crawl_data/pexels
    json_list: /mnt/CV_teamz/users/qiming/dataset/pexels/meta_0501+0601.json
    batch_size: 2
    petrel_conf: /mnt/CV_teamz/open_datasets/datasets/LAION-5b/config/petreloss.tmp.conf
    # tokenizer: ${tokenizer}
    filter_strategy: ~
    caption_drop_prob: 0.0
    resize_size: 256
    num_workers: 0
    prefetch_count: 8
    shuffle: false
    drop_last: true

optimizer:
  _target_: torch.optim.AdamW
  lr: 1.0e-4
  weight_decay: 0.01
scheduler:
  _target_: composer.optim.MultiStepWithWarmupScheduler
  t_warmup: 10000ba
  milestones:
    - 100000000ba
# logger:
#   wandb:
#     _target_: composer.loggers.wandb_logger.WandBLogger
#     name: ${name}
#     project: ${project}
#     group: ${name}
#     host: api.wandb.ai
#     token: 30e859c562557e3cb316b5863156a37c09569611
#     mode: offline
callbacks:
  speed_monitor:
    _target_: composer.callbacks.speed_monitor.SpeedMonitor
    window_size: 10
  lr_monitor:
    _target_: composer.callbacks.lr_monitor.LRMonitor
  memory_monitor:
    _target_: composer.callbacks.memory_monitor.MemoryMonitor
  runtime_estimator:
    _target_: composer.callbacks.runtime_estimator.RuntimeEstimator
  # optimizer_monitor:
  #   _target_: composer.callbacks.OptimizerMonitor
trainer:
  _target_: composer.Trainer
  _convert_: partial
  device: gpu
  max_duration: 550000ba
  eval_interval: 550000ba
  precision: amp_fp16
  device_train_microbatch_size: ~
  run_name: ${name}
  progress_bar: true
  log_to_console: false
  log_traces: false
  seed: ${seed}
  scale_schedule_ratio: ${scale_schedule_ratio}
  # load_path: /mnt/CV_teamz/users/zhongyi/outputs/target/ep0-ba5-rank{rank}.pt.tar
  save_folder: /mnt/CV_teamz/users/zhongyi/outputs/model_save_3B_deepspeed
  save_filename: ep{epoch}-ba{batch}-rank{rank}.pt
  save_interval: 5000ba
  save_overwrite: true
  autoresume: false
  deepspeed_config:
    zero_optimization:
      stage: 2
    gradient_accumulation_steps: 1
    gradient_clipping: 1.0
    offload_optimizer_device: none
    offload_param_device: none
    zero3_init_flag: false
